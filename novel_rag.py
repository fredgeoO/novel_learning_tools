# novel_rag.py

import logging
import sys
import os
import time

# å¯ç”¨æ ¹æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO)

# --- å¯¼å…¥æ–°ç±»å’Œå·¥å…· ---
from rag.narrative_graph_extractor import NarrativeGraphExtractor
from utils_chapter import load_chapter_content
from rag.narrative_schema import ANALYTICAL_SCHEMA

# --- å…¬å…±é…ç½® ---
COMMON_CONFIG = {
    "model_name": "qwen3:8b",
    "base_url": "http://localhost:11434",
    "temperature": 0.0,
    "default_num_ctx": 8192,
    "remote_api_key": os.getenv("ARK_API_KEY"),
    "remote_base_url": "https://ark.cn-beijing.volces.com/api/v3",
    "remote_model_name": "doubao-seed-1-6-250615",
    "selected_schema": ANALYTICAL_SCHEMA,
    "schema_name": "åˆ†ææ¨¡å¼ (Analytical Schema)"
}
def clean_cache():
    """æ¸…ç†æŸåçš„ç¼“å­˜æ–‡ä»¶"""
    import shutil
    cache_dir = "./cache/graph_docs"
    if os.path.exists(cache_dir):
        shutil.rmtree(cache_dir)
        os.makedirs(cache_dir, exist_ok=True)
        print("âœ… ç¼“å­˜ç›®å½•å·²æ¸…ç†")

# 1. æ›¿æ¢åŸæœ‰çš„ load_text å‡½æ•°
def load_text(novel_name="ä¸œäº¬ç—…æ‹å¥³å‹", chapter_file="ç¬¬ä¸€ç«  å€Ÿè´·å°‘å¥³.txt"):
    """åŠ è½½ç« èŠ‚æ–‡æœ¬çš„é€šç”¨å‡½æ•° (ä½¿ç”¨é»˜è®¤å°è¯´ç« èŠ‚)"""
    print(f"\næ­£åœ¨åŠ è½½ç« èŠ‚å†…å®¹: {novel_name} - {chapter_file}...")
    loaded_result = load_chapter_content(novel_name, chapter_file)

    if isinstance(loaded_result, tuple) and len(loaded_result) > 0:
        original_text = loaded_result[0]
        load_success = loaded_result[1] if len(loaded_result) > 1 else True
        if not load_success:
            print("è­¦å‘Šï¼šç« èŠ‚å†…å®¹åŠ è½½å¯èƒ½æœªå®Œå…¨æˆåŠŸã€‚")
        if original_text:
            print(f"âœ… æ–‡æœ¬åŠ è½½æˆåŠŸï¼Œé•¿åº¦: {len(original_text)} å­—ç¬¦")
        return original_text
    else:
        print(f"âŒ é”™è¯¯ï¼šload_chapter_content è¿”å›äº†æ„å¤–çš„ç±»å‹ {type(loaded_result)} æˆ–ä¸ºç©ºã€‚")
        return None


def create_extractor(local_chunk_size=1024, local_chunk_overlap=128,
                     remote_chunk_size=2048, remote_chunk_overlap=256,
                     use_local=True):
    """åˆ›å»º NarrativeGraphExtractor å®ä¾‹çš„é€šç”¨å‡½æ•°"""
    config = COMMON_CONFIG.copy()
    extractor = NarrativeGraphExtractor(
        model_name=config["model_name"],
        base_url=config["base_url"],
        temperature=config["temperature"],
        default_num_ctx=config["default_num_ctx"],
        default_chunk_size=local_chunk_size if use_local else remote_chunk_size,
        default_chunk_overlap=local_chunk_overlap if use_local else remote_chunk_overlap,
        remote_api_key=config["remote_api_key"],
        remote_base_url=config["remote_base_url"].strip(),  # å»æ‰ç©ºæ ¼
        remote_model_name=config["remote_model_name"],
        allowed_nodes=config["selected_schema"]["elements"],
        allowed_relationships=config["selected_schema"]["relationships"],
    )

    if not use_local and not extractor.use_remote_api:
        print("âš ï¸  è­¦å‘Šï¼šè¿œç¨‹APIé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•æµ‹è¯•è¿œç¨‹æ¨¡å‹")
        print(f"   remote_api_key: {'âœ“' if extractor.remote_api_key else 'âœ—'}")
        print(f"   remote_base_url: {'âœ“' if extractor.remote_base_url else 'âœ—'}")
        print(f"   remote_model_name: {'âœ“' if extractor.remote_model_name else 'âœ—'}")
        return None

    print(f"âœ… Extractor åˆå§‹åŒ–å®Œæˆ ({'æœ¬åœ°' if use_local else 'è¿œç¨‹'}æ¨¡å‹é…ç½®)")
    return extractor


def run_extraction(extractor, text, use_local, test_text_length=None, novel_name="", chapter_name=""):
    """æ‰§è¡Œå›¾è°±æå–çš„é€šç”¨å‡½æ•°"""
    model_name = "æœ¬åœ°æ¨¡å‹ (Ollama)" if use_local else "è¿œç¨‹æ¨¡å‹ (è±†åŒ…API)"
    print(f"\n" + "=" * 60)
    print(f"å¼€å§‹æµ‹è¯• {model_name}...")
    if test_text_length:
        print(f"æµ‹è¯•æ–‡æœ¬é•¿åº¦: {test_text_length} å­—ç¬¦")
    print("=" * 60)

    try:
        # ä½¿ç”¨å¸¦ç¼“å­˜çš„æå–æ–¹æ³•
        result, duration, status, chunks = extractor.extract_with_cache(
            text=text,
            novel_name=novel_name,
            chapter_name=chapter_name,
            num_ctx=extractor.default_num_ctx,
            chunk_size=extractor.default_chunk_size,
            chunk_overlap=extractor.default_chunk_overlap,
            merge_results=True,
            verbose=True,
            use_cache=True
        )
        print(f"âœ… {model_name} æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {duration:.2f} ç§’")
        return result, duration, status, chunks
    except Exception as e:
        print(f"âŒ {model_name} æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, 0, 2, []

def display_results(extractor, result, duration, status, chunks, title_suffix=""):
    """æ˜¾ç¤ºæå–ç»“æœçš„é€šç”¨å‡½æ•°"""
    if not result:
        print(f"âŒ {title_suffix}æ— ç»“æœå¯æ˜¾ç¤º")
        return

    print(f"\n" + "=" * 70)
    print(f"ã€{title_suffix}ã€‘")
    print("=" * 70)

    status_msg = {0: "å…¨éƒ¨æˆåŠŸ", 1: "éƒ¨åˆ†æˆåŠŸ", 2: "å…¨éƒ¨å¤±è´¥"}
    print(f"æ€»è€—æ—¶: {duration:.2f} ç§’")
    print(f"æœ€ç»ˆçŠ¶æ€: {status_msg.get(status, 'æœªçŸ¥')}")

    if chunks:
        print(f"\n--- å„åˆ†å‰²å—ç»“æœæ‘˜è¦ ---")
        for i, chunk_res in enumerate(chunks):
            nodes_cnt = len(getattr(chunk_res, 'nodes', []))
            rels_cnt = len(getattr(chunk_res, 'relationships', []))
            print(f"  å— {i + 1}: èŠ‚ç‚¹ {nodes_cnt} ä¸ª, å…³ç³» {rels_cnt} ä¸ª")

    extractor.display_graph_document(result, f"{title_suffix}ç»“æœ")

    print("\n" + "=" * 70)


# --- æµ‹è¯•å‡½æ•° ---
def test_single_model(original_text, novel_name="ä¸œäº¬ç—…æ‹å¥³å‹", chapter_name="ç¬¬ä¸€ç«  å€Ÿè´·å°‘å¥³"):
    """åŸå§‹çš„å•ä¸€æ¨¡å‹æµ‹è¯•"""
    print(f"å·²é€‰æ‹©: {COMMON_CONFIG['schema_name']}")

    # åˆ›å»ºæå–å™¨ (é»˜è®¤ä½¿ç”¨æœ¬åœ°é…ç½®)
    extractor = create_extractor(use_local=True)
    if not extractor:
        return

    # æ‰§è¡Œæå– (ä½¿ç”¨æœ¬åœ°æ¨¡å‹)
    result, duration, status, chunks = run_extraction(
        extractor, original_text, use_local=True,
        novel_name=novel_name, chapter_name=chapter_name
    )

    # æ˜¾ç¤ºç»“æœ
    display_results(extractor, result, duration, status, chunks, "å™äº‹å›¾è°±æå–ç»“æœ")

    print("\nã€è¯´æ˜ã€‘")
    print(f"1. ä½¿ç”¨äº† {COMMON_CONFIG['schema_name']}ã€‚")
    print("2. æ–‡æœ¬å·²è¢«åˆ†å‰²å¤„ç†ï¼Œæ˜¾è‘—æé«˜äº†å¤„ç†é€Ÿåº¦ã€‚")
    print("3. æ¯ä¸ªå—ç‹¬ç«‹å¤„ç†ï¼Œç»“æœå·²å°è¯•åˆå¹¶ã€‚")
    print("4. åˆå¹¶é€»è¾‘æ˜¯åŸºç¡€çš„ï¼šèŠ‚ç‚¹æŒ‰ ID å’Œ Type åˆå¹¶ï¼Œå…³ç³»ç›´æ¥ç´¯åŠ ã€‚")


def compare_models_test(original_text, novel_name="ä¸œäº¬ç—…æ‹å¥³å‹", chapter_name="ç¬¬ä¸€ç«  å€Ÿè´·å°‘å¥³"):
    """æ¯”è¾ƒæœ¬åœ°å’Œè¿œç¨‹æ¨¡å‹çš„æ‰§è¡Œæ—¶é—´å’Œç»“æœå·®å¼‚"""
    print(f"å·²é€‰æ‹©: {COMMON_CONFIG['schema_name']}")

    # ç§»é™¤äº†2000å­—ç¬¦é™åˆ¶ï¼Œä½¿ç”¨å®Œæ•´æ–‡æœ¬
    test_text = original_text
    test_chapter_name = f"{chapter_name}_å¯¹æ¯”æµ‹è¯•"
    print(f"\næµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")

    # åˆ›å»ºæå–å™¨ (æœ¬åœ°å’Œè¿œç¨‹ä½¿ç”¨ä¸åŒçš„åˆ†å—é…ç½®)
    local_extractor = create_extractor(use_local=True)
    remote_extractor = create_extractor(use_local=False)

    if not local_extractor or not remote_extractor:
        print("âŒ æå–å™¨åˆå§‹åŒ–å¤±è´¥")
        return

    results = {}

    # æµ‹è¯•æœ¬åœ°æ¨¡å‹
    local_result, local_duration, local_status, local_chunks = run_extraction(
        local_extractor, test_text, use_local=True,
        test_text_length=len(test_text),
        novel_name=novel_name,
        chapter_name=f"{test_chapter_name}_æœ¬åœ°"
    )
    results['local'] = {
        'result': local_result,
        'duration': local_duration,
        'status': local_status,
        'chunks': local_chunks
    }

    # æµ‹è¯•è¿œç¨‹æ¨¡å‹
    remote_result, remote_duration, remote_status, remote_chunks = run_extraction(
        remote_extractor, test_text, use_local=False,
        test_text_length=len(test_text),
        novel_name=novel_name,
        chapter_name=f"{test_chapter_name}_è¿œç¨‹"
    )
    results['remote'] = {
        'result': remote_result,
        'duration': remote_duration,
        'status': remote_status,
        'chunks': remote_chunks
    }

    # --- å¯¹æ¯”ç»“æœ ---
    print("\n" + "=" * 80)
    print("ã€æ¨¡å‹å¯¹æ¯”æµ‹è¯•ç»“æœã€‘")
    print("=" * 80)

    print(f"ä½¿ç”¨æ¨¡å¼: {COMMON_CONFIG['schema_name']}")
    print(f"æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")

    # æ€§èƒ½å¯¹æ¯”
    print(f"\n--- æ€§èƒ½å¯¹æ¯” ---")
    local_duration = results['local'].get('duration', 0)
    remote_duration = results['remote'].get('duration', 0)

    if local_duration > 0 and remote_duration > 0:
        print(f"  æœ¬åœ°æ¨¡å‹è€—æ—¶: {local_duration:.2f} ç§’")
        print(f"  è¿œç¨‹æ¨¡å‹è€—æ—¶: {remote_duration:.2f} ç§’")
        if local_duration < remote_duration:
            speedup = remote_duration / local_duration
            print(f"  ğŸ’¡ æœ¬åœ°æ¨¡å‹å¿« {speedup:.1f} å€")
        else:
            slowdown = local_duration / remote_duration
            print(f"  ğŸŒ è¿œç¨‹æ¨¡å‹å¿« {slowdown:.1f} å€")
    elif local_duration > 0:
        print(f"  æœ¬åœ°æ¨¡å‹è€—æ—¶: {local_duration:.2f} ç§’")
        print(f"  è¿œç¨‹æ¨¡å‹æµ‹è¯•å¤±è´¥")
    elif remote_duration > 0:
        print(f"  æœ¬åœ°æ¨¡å‹æµ‹è¯•å¤±è´¥")
        print(f"  è¿œç¨‹æ¨¡å‹è€—æ—¶: {remote_duration:.2f} ç§’")
    else:
        print("  ä¸¤ç§æ¨¡å‹æµ‹è¯•å‡å¤±è´¥")

    # ç»“æœè´¨é‡å¯¹æ¯”
    print(f"\n--- ç»“æœè´¨é‡å¯¹æ¯” ---")
    local_nodes = len(getattr(results['local'].get('result'), 'nodes', [])) if results['local'].get('result') else 0
    local_rels = len(getattr(results['local'].get('result'), 'relationships', [])) if results['local'].get(
        'result') else 0
    remote_nodes = len(getattr(results['remote'].get('result'), 'nodes', [])) if results['remote'].get('result') else 0
    remote_rels = len(getattr(results['remote'].get('result'), 'relationships', [])) if results['remote'].get(
        'result') else 0

    print(f"  æœ¬åœ°æ¨¡å‹: èŠ‚ç‚¹ {local_nodes} ä¸ª, å…³ç³» {local_rels} ä¸ª")
    print(f"  è¿œç¨‹æ¨¡å‹: èŠ‚ç‚¹ {remote_nodes} ä¸ª, å…³ç³» {remote_rels} ä¸ª")

    # æ˜¾ç¤ºç»“æœè¯¦æƒ…
    if results['local'].get('result'):
        print(f"\n--- æœ¬åœ°æ¨¡å‹ç»“æœæ‘˜è¦ ---")
        display_results(local_extractor, results['local']['result'], 0, 0, [], "æœ¬åœ°æ¨¡å‹")

    if results['remote'].get('result'):
        print(f"\n--- è¿œç¨‹æ¨¡å‹ç»“æœæ‘˜è¦ ---")
        display_results(remote_extractor, results['remote']['result'], 0, 0, [], "è¿œç¨‹æ¨¡å‹")

    print("\n" + "=" * 80)
    print("ã€æµ‹è¯•è¯´æ˜ã€‘")
    print("1. æœ¬åœ°æ¨¡å‹ï¼šä½¿ç”¨ Ollama è¿è¡Œçš„ qwen3:8b")
    print("2. è¿œç¨‹æ¨¡å‹ï¼šä½¿ç”¨ç«å±±æ–¹èˆŸè±†åŒ… API")
    print("3. ä½¿ç”¨å®Œæ•´æ–‡æœ¬è¿›è¡Œæµ‹è¯•")
    print("4. æ€§èƒ½å—ç½‘ç»œã€æ¨¡å‹è´Ÿè½½ç­‰å¤šç§å› ç´ å½±å“")
    print("=" * 80)


def test_remote_only(original_text, novel_name="ä¸œäº¬ç—…æ‹å¥³å‹", chapter_name="ç¬¬ä¸€ç«  å€Ÿè´·å°‘å¥³"):
    """åªæµ‹è¯•è¿œç¨‹æ¨¡å‹"""
    print(f"å·²é€‰æ‹©: {COMMON_CONFIG['schema_name']}")

    # ç§»é™¤äº†2000å­—ç¬¦é™åˆ¶ï¼Œä½¿ç”¨å®Œæ•´æ–‡æœ¬
    test_text = original_text
    print(f"\næµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")

    # åˆ›å»ºæå–å™¨ (ä½¿ç”¨è¿œç¨‹é…ç½®)
    extractor = create_extractor(use_local=False)
    if not extractor:
        return

    # æ‰§è¡Œæå– (å¼ºåˆ¶ä½¿ç”¨è¿œç¨‹æ¨¡å‹)
    result, duration, status, chunks = run_extraction(
        extractor, test_text, use_local=False,
        test_text_length=len(test_text),
        novel_name=novel_name,
        chapter_name=f"{chapter_name}_è¿œç¨‹_only"
    )

    # æ˜¾ç¤ºç»“æœ
    display_results(extractor, result, duration, status, chunks, "è¿œç¨‹æ¨¡å‹æµ‹è¯•ç»“æœ")

    print("\nã€è¯´æ˜ã€‘")
    print("1. ä½¿ç”¨è¿œç¨‹æ¨¡å‹ï¼šç«å±±æ–¹èˆŸè±†åŒ… API")
    print("2. æ–‡æœ¬å·²è¢«åˆ†å‰²å¤„ç†")
    print("3. æ¯ä¸ªå—ç‹¬ç«‹å¤„ç†ï¼Œç»“æœå·²å°è¯•åˆå¹¶")


# 2. æ›¿æ¢åŸæœ‰çš„ if __name__ == "__main__": å—
if __name__ == "__main__":
    # 1. ç›´æ¥åŠ è½½é»˜è®¤æ–‡æœ¬ (ä¸å†éœ€è¦ç”¨æˆ·é€‰æ‹©)
    novel_name = "ä¸œäº¬ç—…æ‹å¥³å‹"
    chapter_file = "ç¬¬ä¸€ç«  å€Ÿè´·å°‘å¥³.txt"
    chapter_name = "ç¬¬ä¸€ç«  å€Ÿè´·å°‘å¥³"

    print(f"--- ä½¿ç”¨é»˜è®¤å°è¯´ç« èŠ‚: {novel_name} - {chapter_file} ---")
    original_text = load_text(novel_name, chapter_file)  # ä½¿ç”¨æŒ‡å®šå‚æ•°

    if not original_text:
        print("âŒ æ— æ³•åŠ è½½æ–‡æœ¬ï¼Œç¨‹åºé€€å‡ºã€‚")
        sys.exit(1)

    # 2. è¯¢é—®ç”¨æˆ·è¦è¿è¡Œå“ªç§æµ‹è¯•
    print("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å•ä¸€æ¨¡å‹æµ‹è¯•")
    print("2. æœ¬åœ°vsè¿œç¨‹æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("3. ä»…æµ‹è¯•è¿œç¨‹æ¨¡å‹")

    choice = input("è¯·è¾“å…¥é€‰æ‹© (1ã€2 æˆ– 3): ").strip()

    # 3. æ ¹æ®é€‰æ‹©è°ƒç”¨ç›¸åº”çš„æµ‹è¯•å‡½æ•°ï¼Œå¹¶ä¼ é€’å·²åŠ è½½çš„æ–‡æœ¬
    if choice == "2":
        compare_models_test(original_text, novel_name, chapter_name)
    elif choice == "3":
        test_remote_only(original_text, novel_name, chapter_name)
    else:
        test_single_model(original_text, novel_name, chapter_name)
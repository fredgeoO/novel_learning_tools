第34章 数据融合异常

几个在实验室的师兄都点开链接，打算观摩一下周昀的独门秘籍。

　　就连刚刚趴下的邱彦都重新坐直了身子。

　　几人了看了一会儿，都不由发出感叹。

　　“我愿称之为——研究生新手入门宝典！”

　　“确实，我们那时候要有这东西，得少走多少弯路，不说别的，就这装环境，那时候就卡了我一两个月，

　　学怎么用github又是一两周，学会怎么找文献又是一两周，各种杂七杂八的东西学下来，半个学期就过去了，

　　而且这玩意儿又没有系统性的教程，都是自己一点点上网找的，不过你们这倒是好了，有周昀这东西，能省下不少时间。”

　　“对你们有帮助就行，如果别人有需要的话直接给就好了，只是别让人拿着我的东西去收费就好，看完觉得有帮助给我点个Star呗。”

　　“点了，要我说，你这玩意儿迟早得火！”

　　“那借你吉言了。”

　　短暂的吵闹过后，实验室又恢复了平静。

　　周昀看着屏幕上的实验记录，第一次感觉有些棘手。

　　能够支撑模型运行的核心代码他上周就写完了，然后设置了几组实验，跑了六天，今天刚好出结果。

　　只是这结果，有些不尽如人意。

　　在选择股票相同的情况下，甚至还没有之前那个只能接受数值和文本数据的阉割版模型效果好。

　　这就是AI领域的问题之一，模型完全是黑盒的，你永远不知道你的数据在模型里是怎么变化传输的，可能某一行代码出了问题，就会导致各种奇奇怪怪的问题。

　　不过还好，周昀在写代码的时候加入了大量的调试代码，因为每跑一次实验需要的时间太长了，

　　甚至这次他并没有用到所有的数据，只用了其中的一部分，跑一组实验就得一周，这还是64张H100的显卡集群的情况下，

　　如果用上全部的数据的话，虽然时间上不会是简单的倍乘关系，但至少也得两周。

　　但这也就是第一次训练时候需要大量数据才要这么久，等第一次训练好了，后续的再有新的数据，就不需要从头训练，只需要利用新的数据微调就行。

　　现在他就在看输出日志，观察到底是在哪一个环节出了问题，为了衡量模型的效果好坏，

　　他在数据预处理，数据融合，模型训练，结果输出这几个方面设计了几个指标。

　　经过观察，他大概确认了最为可能的一个原因。

　　数据融合异常。

　　因为模型接受的数据是多种模态的，所以在预处理之后还有一个数据融合阶段。

　　根据实验日志来看，问题就出现在了这一阶段。

　　原本的数据融合算法在只有两种模态数据的时候，效果很好，但是当数据的模态数量逐渐上升，

　　一些原本没有发现的bug逐渐显现出来，这也是导致最终效果不如原来模型的最为重要的原因。

　　当然，也可能是因为过拟合，数据泄露，这种普遍性的问题，只不过仅根据这次的输出日志来看，可能性不大。

　　“嗯......特征维度贡献方差过大？”划动滚轮的手指停下，周昀敏锐地看到了一条异常的输出。

　　说人话就是，模型在融合信息的时候没有一个轻重缓急，对所有模态的数据都一视同仁，平等对待了所有输入。

　　这在模态少的时候可能适用，因为数据输入之前，在无形之中其实是多了一个人工筛选的步骤。

　　比如你要预测股票的涨跌，相比于各种专家的视频分析，你可能会更加相信各种金融指标，所以你就会下意识地选择各种数字指标输入模型，而不是专家的视频分析。

　　这就隐含地为数据赋予了权重，虽然代码里没有，但它确实是真实存在的。

　　不过人工筛选终究是有一些小问题的，在金融这个反人类的领域，光凭经验很多时候容易做出错误的判断。

　　“也就是说，在数据融合的时候，缺少了一个‘智能筛选’的步骤，让模型知道，哪些数据重要，哪些数据不重要。”

　　“数据筛选.......”周昀手指轻轻敲打着桌面，思考着解决办法。

　　如果只是单纯的逻辑判断，肯定不行，这样太死板，还不如人来筛选。

　　置信度？

　　周昀想了一下，也觉得不行。

　　置信度其实就是模型对自己输出结果的把握大小，例如一个分类任务，最终模型的输出会在Softmax函数的作用下，变成一连串的概率，

　　比如分类到A的概率为80%，B任务的概率为10%以此类推。

　　那么置信度就是采用概率大于一定数值的结果。

　　这东西听上去玄乎，实际上也是一种比较死板的逻辑判断。

　　除了这两种，筛选数据的方法其实还有很多，不过周昀都不满意，因为这些方法从他们的底层逻辑来看，都没有达到他想要看到的“智能”。

　　突然，周昀手指一顿。

　　如果从另一方面来看，数据筛选，还可以看作是一种数据蒸馏。

　　数据蒸馏其实很好理解，蒸馏大家都知道，那么数据蒸馏就是通过某种手段将数据集提纯的方法。

　　恰好，周昀发在NeurIPS上的AgileEdge这篇论文里就有一种数据蒸馏的方法，因为想要缩小模型，就等于缩小参数量，两者之间其实有着异曲同工之妙。

　　直接拿过来用肯定不行，不过周昀感觉只要稍作修改，应该能达到他想要的效果，因为当初设计这种数据蒸馏方法的时候，就已经着眼于“智能”二字。

　　找到之前的论文代码，周昀直接将那段封装好的数据蒸馏方法copy过来，然后再根据现有的模型进行修改。

　　因为代码量不大，他就没有用AI，而且AI也未必能准确理解他要怎么改，不如自己动手。

　　直到晚上快到六点，他才靠着椅子，伸了个懒腰。

　　终于改完了。

　　划动着鼠标滚轮，看着已经成功运行的代码，他心里涌现出一股巨大的满足感。

　　这就是科研的爽感来源，当你解决了一个难题之后所带来的快感，是其他任何事情都不能带给你的。

　　等了一会儿，直到确认第一个epoch顺利开始后，周昀断开了与服务器的连接。

　　他在服务器上设置了几组实验，这次跑完估计得要两周，不过他也可以趁着这段时间放松一下。

　　如果顺利的话，之前那件事情，也差不多该迎来一个结局了。
第59章 毕业论文选题

周一，刚上完课的周昀吃完中饭甚至没有休息，就直奔邓永华办公室。

　　无他，他要提前毕业！

　　上午这种水课简直是在浪费他的时间，睡觉还能养足精神呢，上这种水课完全就是精神和肉体的双重折磨。

　　“老师，我想提前毕业。”周昀眼神异常坚定地看着邓永华。

　　后者对周昀的想法并不感到奇怪，毕竟提前毕业这事情还是他提出来的。

　　“决定了？”

　　“决定了！”

　　“好，学分上的事情我帮你问问，虽然不符合规矩，但是规矩是死的，人是活的，别人的话我不好说，但是你的话，学校这边应该没什么问题，

　　不过既然想要提前毕业，毕业论文肯定要写的，你可以想一想，如果你想快一点，就直接跳过开题，和这一届研三的学长一起，

　　如果不着急就先开题再写论文，和明年邱彦他们一起毕业，怎么选看你自己。”

　　稍作思考，周昀当场就给出了自己的决定：“我要和这一届研三学长一起毕业，这课他真的是一节都不想再多上了！”

　　邓永华点点头：“既然你决定了，我肯定是支持的。”说着他拿出几张纸：“不过该有的程序还是要有的，这是开题的表格，你先填好，到时候走程序也能方便一些。”

　　“那平时的课还要去上吗？”

　　“不用了，这段时间你专心搞你的毕业论文就好，不过十二月份咱们要去温哥华参会，最好是在这段时间内搞完，等开完会回来估计就是最终的答辩了，一个月的时间会不会太紧了？”

　　“不会！我肯定会在开会前弄完的。”

　　“对了，就算是毕业论文也别想着蒙混过关，你想要提前毕业，要求只会更加严格，而且毕业论文以后是会跟你一辈子的东西，一定要认真对待！”

　　邓永华很是严肃地提醒了一下，他是怕周昀为了赶紧毕业，水一篇质量一般的论文出来。

　　“好，我明白的。”

　　拿着几张纸，回到实验室。

　　周昀坐在位置上思考着毕业论文的选题，手指无意识地敲打着桌面。

　　写过论文的都知道，一个月从零搞一篇毕业论文几乎就是不可能的事情。

　　所以他如果想要完成，从现有的工作出发算是一种方法。

　　他现在做的工作不多，能选的只有俩——模型压缩，多模态大模型。

　　多模态大模型肯定不行，跑个实验一个月就过去了，更别说什么毕业论文了。

　　模型压缩？其实也不太好做，跑实验也要不少时间。

　　那他剩下的只有一条路——搞理论。

　　他说的搞理论也不是纯理论，而是那种只需要小型验证性实验的模型基础架构方面的研究，比如提出Transform的《Attention Is All You Need》，实验部分其实并不算多。

　　直接提出一种全新的技术模型架构？

　　说实话，这个问题他想过，而且时间很久，久到可以追溯到上辈子。

　　虽然上辈子周昀没这么聪明，但是当他第一次接触到Transform的时候就在想，他能不能研究出一种更加厉害的基础架构。

　　当然了，这在上辈子完全就是幻想。

　　所以平时有空的时候他就会抽出时间思考这个问题，所以邱彦他们经常能看到周昀独自一个人坐在位置上发呆，而且一坐就是几个小时。

　　但哪怕他觉得自己现在已经足够聪明，可是经过近半年的思考，他还是没能想到什么全新的架构，终究还是被束缚在Transform的框架之下。

　　不过他也没有气馁，毕竟这东西要是研究出来，说一句名垂千古都不为过。

　　更何况他还年轻。

　　既然新的架构不行，就只能从他熟悉的两个领域入手了。

　　他的手指一顿，突然想到了一个非常好的选题，如果能做出来，贡献也绝对是巨大的。

　　这个选题就是——多模态融合中的最优传输理论。

　　多模态学习的核心是如何将不同模态（视觉、语言）的特征空间对齐，当前的方法通常使用的是交叉注意力机制，甚至是更为简单的点积或余弦相似度。

　　而最优传输（Optimal Transport， OT）是一种数学理论，致力于寻找将质量或概率从一种构型转移到另一种构型的最有效方式，从而最小化给定的成本。

　　他的想法就是将对齐问题建模为OT问题，当然，这个OT问题肯定会非常难，因为每一个特征的维度都是非常高的，而多模态的特征又非常多。

　　所以他就联想到了人类的大脑，人脑在处理不同感官信息（视觉、听觉、触觉）时，似乎在底层存在着一种统一的“意识流”，

　　各种模态的信息涌入后，被映射并在这个流中进行交换、融合和理解，比如闻着榴莲吃西瓜，就会产生一种通感。

　　而他要做的就是，如何将这个所谓的‘意识流’用数学的方法表现出来，他能想到的最为接近的理论就是OT理论。

　　至于为什么一定要将信息融合其实也很好理解，打个比方，你要向一个来自外星系、完全不懂地球文化的外星人解释什么是“苹果”，

　　你不能只给它看一张苹果的图片，或者只给它一个苹果吃。

　　因为这些信息对它来说都是割裂的、无法理解的，所以我们需要将每种信息变成一种感觉，比如苹果可能是甜的，酸的，可能是绿的，红的......

　　而人在学习一个陌生的事物时候也是差不多的流程，比如神农尝百草，先了解这个草药不同的特性，然后再给它下一个定义。

　　同理，要让AI理解世界，这个步骤也是需要的，你得先让AI理解，苹果的一些基本特性，这也是很多大模型都在做的一个步骤。

　　接下来的一步便是信息融合，也就是告诉AI一个更加高级的统一语义空间，告诉它，虽然信息的模态不同，但他们描述的都是同一种东西，这就是融合的步骤。

　　这也是现代多模态大模型能同时处理不同模态信息的原理。

　　只不过在将不同模态信息纳入这个统一语义空间的语义空间时，现在的方法仍然有很多的不足。

　　这个问题也是真正实现AGI路上的一块绊脚石。
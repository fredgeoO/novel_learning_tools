第5章 不好意思，我打断一下。

四个学生过后，很快就轮到周昀了。

　　“周昀同学你好，你没有带简历，要不先做个自我介绍，然后讲一下你今后三年的规划？”

　　周昀点点头：“我叫周昀，本科毕业于.........”

　　简单介绍了一下自己的毕业学校，初试成绩，自我介绍就算完了，毕竟过去平淡的二十年真没什么好介绍的。

　　“对于未来三年，我的想法是认真科研，争取读博......”

　　当邓永华听到读博两个字的时候，看周昀的眼神都有些发光了，就像是触发了关键词一样。

　　坐在他身边的邱彦和沈瑞两人都有些钦佩地看向周昀。

　　这小子有点虎啊，读博？这是一般人能读的吗？

　　等周昀说完后，邓永华点点头：“刚刚听你说了，你对科研很感兴趣，虽然你五道题全都答出来了，

　　但是想要搞好科研光靠这些是远远不够的，你觉得你在科研方面有哪些优势？”

　　全答出来了？！

　　邱彦和沈瑞，包括旁边坐着的四位同学看着周昀的表情都不一样了。

　　邱彦和沈瑞想的是：这小学弟有点东西啊，如果不出意外的话，这学生老师肯定要收下的，别的不说，就这基础就不是一般人能有的。

　　而另外四人想的则是：坏，遇到大佬了！心中都不由得为自己捏了一把汗。

　　“老师，其实我觉得我在科研方面还算是有点天赋，不过这样说您也未必会信，我准备了一个PPT，要不我简单汇报一下？”

　　和这种科研型的导师讲话，最好的说话方式就是实话实说。

　　邓永华眉头微挑：“可以啊，当然没问题，这里就有线，你带电脑了吗？要是没带，我的电脑可以暂时借你用一下。”

　　“我带电脑了。”周昀从身后的书包中拿出电脑，熟练的连上了大屏幕的HDMI线。

　　在电脑开机的时候，墙边的四位同学只感觉自己再次受到了暴击。

　　不是哥们？咱们不是面试来了吗，你这咋还汇报上了？

　　虽然不知道周昀要汇报什么，但是这种场合下，没点真东西，敢随便乱讲话吗？

　　周昀的实力在他们心里再次提高了一个档次。

　　而邱彦和沈瑞的表情就变的有些复杂了，看向周昀的眼神带着几分同情。

　　虽然邓永华平时人很好，但是牵扯到学术问题上就会相当严肃，被骂那都是基本操作。

　　每次组会的时候，要是没人被骂，那才是真的奇了怪了。

　　别看邓老师现在一脸笑容，等会儿他就会让你知道，什么叫做科研的严谨。

　　周昀起身走到大屏幕旁边。

　　他要开始装....不对，是汇报了。

　　“AgileEdge: Adaptive Co-Optimization for Pervasive Low-Latency Edge AI，这是我今天要汇报的内容。”

　　一口流利的英语让邓永华满意地点点头，不过表情却是变的严肃了不少。

　　还没等周昀继续，他就开口问道：“你是要汇报论文吗？这是什么期刊或者会议上的论文？作者是谁？......”

　　邱彦和沈瑞都是一副果然如此的样子，他们记得当初他们第一次汇报的时候虽然有着新手保护期，但也被邓老师问的死去活来的。

　　不过当他们看向周昀时，却发现他脸上没有一丝的紧张。

　　事实也确实如此，三年下来，周昀都不知道经历过多少组会了，紧张？那是不存在的。

　　等邓老师话音落下，周昀一脸从容的回答：“这是我想要研究的课题，根据我的调研，暂时还没有以这篇文章命名的论文。”

　　“哦？这个题目是你自己想的？”周昀的回答让他有些意外，就算是他手下那几个要读博的研三的学生，也没有谁的研究课题是完全独立想出来的。

　　这对于一个研零的学生来说已经是非常不错了。

　　“你继续。”

　　周昀翻到下一页PPT，没有文字，PPT上是一些著名的AI公司的LOGO：“这些都是现在比较著名的AI公司，

　　GPT，claude，gemini这都是现在世界上顶尖的大模型，不可否认的是，这些大模型的性能都非常强，但相对应的，训练他们所耗费的资源也是海量。

　　一个先进的图像识别模型可能需要几十甚至上百兆的内存，数以亿计的计算量。

　　它们就像高性能的跑车，必须在云端数据中心这样的大跑道上才能发挥实力，但是现实生活中，大家的设备都是电脑，手机，摄像头等等。”

　　说到这里周昀停了一下，将PPT翻到下一页。

　　老师没有提问，那他就继续讲。

　　“这种情况下，我们面临一个巨大的挑战：如何让庞大、复杂的AI模型，在这些资源有限的“小设备”上，也能跑得又快又好，还能实时响应？

　　以下四点是我认为的需要解决的几个痛点：

　　1.尺寸不符：大模型在小设备上跑不动，或直接装不下。

　　2.速度滞后：即使勉强能跑，响应速度也慢，用户体验差。

　　3.能耗巨大：小设备电池续航有限，大模型会迅速耗尽电量。

　　4.网络依赖：依赖云端意味着有延迟，且断网就失效，隐私也难以保障。”

　　“不好意思，我打断一下。”

　　“老师您说。”

　　“你刚才提到了这些大模型性能虽强，但资源消耗巨大，而现在你想把这些大模型塞进小设备里，其中的难点我理解，

　　但是，既然这些顶尖大模型在云端表现如此出色，为什么我们非要执着于把它们硬塞进边缘设备？

　　云端计算的便捷性和可扩展性难道不更符合AI发展的趋势吗？边缘部署的必要性到底有多强？”

　　这个问题问的非常刁钻，如果周昀不能回答，那就算是从根本上否定了研究的必要性。

　　“老师的问题确实非常关键，如您所言，云端大模型在性能和可扩展性上确实有无可比拟的优势，

　　但是大模型的基石是数据！

　　在金融、医疗、国家安全等高度敏感的行业，数据“不出境”或“不出厂区”是严格的法律法规要求。

　　这种情况下，任何云端的数据传输都是具有一定风险的，虽然其有强大的安全措施，但其本身就是一个巨大的‘靶心’，

　　一旦云服务遭受网络攻击，影响范围可能是灾难性的，这一点相信老师肯定是有所了解的。”
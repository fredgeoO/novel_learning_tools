# rag/graph_manager.py

import os
import json
import glob
import uuid
import logging
from datetime import datetime
from typing import Dict, Set

# --- ä¿®æ”¹ 1: ä» inputs/rag/config.py å¯¼å…¥ CACHE_DIR ---

from rag.config import CACHE_DIR as DEFAULT_CACHE_DIR

# --- ä¿®æ”¹ 2: å®šä¹‰å­ç›®å½• ---
GRAPH_CACHE_SUBFOLDER = "graph_docs"
# --- ä¿®æ”¹ 3: æ„é€ å®é™…çš„å›¾è°±ç¼“å­˜ç›®å½• ---
GRAPH_CACHE_DIR = os.path.join(DEFAULT_CACHE_DIR, GRAPH_CACHE_SUBFOLDER)
print("GRAPH_CACHE_DIR:" + GRAPH_CACHE_DIR)
# ç¡®ä¿ç›®å½•å­˜åœ¨ (å¯é€‰ï¼Œä½†æ¨è)
os.makedirs(GRAPH_CACHE_DIR, exist_ok=True)

logger = logging.getLogger(__name__)


def load_available_graphs_metadata() -> Dict[str, Dict]: # é»˜è®¤å€¼æ”¹ä¸º GRAPH_CACHE_DIR
    """åŠ è½½æ‰€æœ‰å¯ç”¨å›¾è°±çš„å…ƒæ•°æ®"""
    available_graphs = {}

    path = os.path.join(GRAPH_CACHE_DIR, "*_metadata.json")
    metadata_files = glob.glob(path) # ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒä½¿ç”¨äº†ä¼ å…¥çš„ cache_dir å‚æ•°


    metadata_files.sort(key=os.path.getmtime, reverse=True)

    for meta_file_path in metadata_files:
        try:
            with open(meta_file_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            cache_key = os.path.basename(meta_file_path).replace("_metadata.json", "")

            # â­ï¸ é‡æ–°ç»„ç»‡æ•°æ®ç»“æ„ï¼ŒåŒ¹é…å‰ç«¯æœŸæœ›çš„æ ¼å¼
            # â­ï¸ é‡æ–°ç»„ç»‡æ•°æ®ç»“æ„ï¼ŒåŒ¹é…å‰ç«¯æœŸæœ›çš„æ ¼å¼
            available_graphs[cache_key] = {
                "filters": {
                    "novel_name": metadata.get("novel_name", ""),
                    "chapter_name": metadata.get("chapter_name", ""),
                    "model_name": metadata.get("model_name", ""),
                    "schema_name": metadata.get("schema_name", ""),
                    "chunk_size": metadata.get("chunk_size", ""),
                    "chunk_overlap": metadata.get("chunk_overlap", ""),
                    "num_ctx": metadata.get("num_ctx", "")
                },
                "metadata": {
                    "created_at": metadata.get("created_at", "")
                }
            }

        except Exception as e:
            logger.warning(f"åŠ è½½å…ƒæ•°æ®æ–‡ä»¶ {meta_file_path} æ—¶å‡ºé”™: {e}")
            continue
    return available_graphs


def delete_selected_graph(cache_dir: str = GRAPH_CACHE_DIR, cache_key: str = "") -> bool: # é»˜è®¤å€¼æ”¹ä¸º GRAPH_CACHE_DIR
    """åˆ é™¤æŒ‡å®š cache_key å¯¹åº”çš„å›¾è°±æ•°æ®æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶"""
    if not cache_key:
        return False

    # data_file_path = os.path.join(cache_dir, f"{cache_key}.json") # ä½¿ç”¨ä¼ å…¥çš„æˆ–é»˜è®¤çš„ cache_dir
    # metadata_file_path = os.path.join(cache_dir, f"{cache_key}_metadata.json")
    # å¦‚æœè¦å¼ºåˆ¶åœ¨ graph_docs ä¸‹æ“ä½œï¼š
    data_file_path = os.path.join(GRAPH_CACHE_DIR, f"{cache_key}.json") # å¼ºåˆ¶ä½¿ç”¨ GRAPH_CACHE_DIR
    metadata_file_path = os.path.join(GRAPH_CACHE_DIR, f"{cache_key}_metadata.json")

    # ... (å…¶ä½™é€»è¾‘ä¿æŒä¸å˜ï¼Œä½†ä½¿ç”¨ä¿®æ”¹åçš„è·¯å¾„) ...
    files_deleted = []
    if os.path.exists(data_file_path):
        try:
            os.remove(data_file_path)
            files_deleted.append(f"`{os.path.basename(data_file_path)}`")
            logger.info(f"å·²åˆ é™¤æ•°æ®æ–‡ä»¶: {data_file_path}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ•°æ®æ–‡ä»¶ '{data_file_path}' æ—¶å‡ºé”™: {e}")

    if os.path.exists(metadata_file_path):
        try:
            os.remove(metadata_file_path)
            files_deleted.append(f"`{os.path.basename(metadata_file_path)}`")
            logger.info(f"å·²åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶: {metadata_file_path}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶ '{metadata_file_path}' æ—¶å‡ºé”™: {e}")

    return len(files_deleted) > 0

# ==================== æ¼”ç¤ºæ•°æ®ç®¡ç† ====================

def create_demo_data(cache_dir: str = GRAPH_CACHE_DIR) -> str: # é»˜è®¤å€¼æ”¹ä¸º GRAPH_CACHE_DIR
    """åˆ›å»ºæ¼”ç¤ºå›¾è°±æ•°æ®å’Œå…ƒæ•°æ®æ–‡ä»¶"""
    demo_graph_data = {
        # ... (æ•°æ®ä¿æŒä¸å˜) ...
    }

    demo_cache_key = "demo_" + str(uuid.uuid4())[:8]
    demo_metadata = {
        # ... (å…ƒæ•°æ®ä¿æŒä¸å˜) ...
        "created_at": datetime.now().isoformat()
    }

    # ç¡®ä¿ç›®å½•å­˜åœ¨ (ä½¿ç”¨ GRAPH_CACHE_DIR)
    os.makedirs(GRAPH_CACHE_DIR, exist_ok=True)

    # å†™å…¥å›¾è°±æ•°æ® (ä½¿ç”¨ GRAPH_CACHE_DIR)
    # with open(os.path.join(cache_dir, f"{demo_cache_key}.json"), "w", encoding="utf-8") as f: # åŸæ¥çš„
    with open(os.path.join(GRAPH_CACHE_DIR, f"{demo_cache_key}.json"), "w", encoding="utf-8") as f: # ä¿®æ”¹å
        json.dump(demo_graph_data, f, ensure_ascii=False, indent=2)

    # å†™å…¥å…ƒæ•°æ® (ä½¿ç”¨ GRAPH_CACHE_DIR)
    # with open(os.path.join(cache_dir, f"{demo_cache_key}_metadata.json"), "w", encoding="utf-8") as f: # åŸæ¥çš„
    with open(os.path.join(GRAPH_CACHE_DIR, f"{demo_cache_key}_metadata.json"), "w", encoding="utf-8") as f: # ä¿®æ”¹å
        json.dump(demo_metadata, f, ensure_ascii=False, indent=2)

    logger.info(f"âœ… åˆ›å»ºæ¼”ç¤ºå›¾è°±: {demo_cache_key}")
    return demo_cache_key


def ensure_demo_graph(cache_dir: str = GRAPH_CACHE_DIR) -> str: # é»˜è®¤å€¼æ”¹ä¸º GRAPH_CACHE_DIR
    """ç¡®ä¿å­˜åœ¨æ¼”ç¤ºå›¾è°±ï¼Œè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ª"""
    # æŸ¥æ‰¾å·²å­˜åœ¨çš„æ¼”ç¤ºæ•°æ® (åœ¨ GRAPH_CACHE_DIR ä¸‹æŸ¥æ‰¾)
    # demo_files = [
    #     f for f in os.listdir(cache_dir) # åŸæ¥çš„
    #     if f.startswith('demo_') and f.endswith('.json') and not f.endswith('_metadata.json')
    # ]
    # ä¿®æ”¹ä¸ºåœ¨ GRAPH_CACHE_DIR ä¸‹æŸ¥æ‰¾
    demo_files = []
    if os.path.exists(GRAPH_CACHE_DIR): # å…ˆæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        demo_files = [
            f for f in os.listdir(GRAPH_CACHE_DIR)
            if f.startswith('demo_') and f.endswith('.json') and not f.endswith('_metadata.json')
        ]

    if demo_files:
        # demo_cache_key = demo_files[0].replace('.json', '') # è¿™ä¸ªé€»è¾‘æ˜¯å¯¹çš„
        # ä½†ä¸ºäº†æ¸…æ™°ï¼Œå¯ä»¥æ˜ç¡®æ˜¯ä» GRAPH_CACHE_DIR æ‰¾åˆ°çš„
        demo_cache_key = os.path.splitext(demo_files[0])[0] # os.path.splitext æ›´å¥å£®
        logger.info(f"ğŸ“‚ ä½¿ç”¨ç°æœ‰æ¼”ç¤ºå›¾è°±: {demo_cache_key}")
        return demo_cache_key
    else:
        # return create_demo_data(cache_dir) # åŸæ¥çš„ï¼Œä¼šä¼ é€’ cache_dir
        return create_demo_data() # ä¿®æ”¹åï¼Œä½¿ç”¨ create_demo_data çš„é»˜è®¤å€¼ (GRAPH_CACHE_DIR)

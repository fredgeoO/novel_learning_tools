# test/query.py
import chromadb
from sentence_transformers import SentenceTransformer
import torch

def load_embed_model():
    """åªåœ¨æŸ¥è¯¢æ—¶æŒ‰éœ€åŠ è½½ embedding æ¨¡å‹ï¼ˆå…¶å®ä¹Ÿå¯ä»¥ç¼“å­˜ï¼Œä½†æŸ¥è¯¢é¢‘ç‡ä½ï¼Œå½±å“ä¸å¤§ï¼‰"""
    print("ğŸ” åŠ è½½ Qwen3 Embedding æ¨¡å‹ç”¨äºæŸ¥è¯¢...")
    return SentenceTransformer(
        "Qwen/Qwen3-Embedding-8B",
        tokenizer_kwargs={"padding_side": "left"},
        trust_remote_code=True,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )

def query_chroma(query_text: str, n_results: int = 3):
    # 1. è¿æ¥å·²æœ‰æ•°æ®åº“ï¼ˆä¸é‡æ–°å…¥åº“ï¼ï¼‰
    client = chromadb.PersistentClient(path="test/chroma_qwen3")
    collection = client.get_collection("chapters")

    # 2. ä»…å¯¹æŸ¥è¯¢æ–‡æœ¬ç”Ÿæˆ embedding
    embed_model = load_embed_model()
    query_emb = embed_model.encode([query_text], prompt_name="query")

    # 3. æŸ¥è¯¢å¹¶æ‰“å°ç»“æœ
    results = collection.query(
        query_embeddings=query_emb.tolist(),
        n_results=n_results
    )

    for i, (doc, _id) in enumerate(zip(results['documents'][0], results['ids'][0])):
        print(f"\n--- ç»“æœ {i+1} (ID: {_id}) ---")
        print(doc[:300] + "..." if len(doc) > 300 else doc)

if __name__ == "__main__":
    query_chroma("ç”·ä¸»è§’æ˜¯è°")